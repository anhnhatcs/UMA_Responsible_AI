Log files: logs/visa_wall_2685550.out/err (Mode: custom)
==========================================
THE VISA WALL: LLM BIAS EVALUATION
==========================================
Job ID: 2685550
Job Name: visa_wall_bias
Node: uc2n902
Partition: gpu_a100_il
GPU(s): 3
CPUs: 
Memory:  MB
Workspace: /pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI
Start Time: Sat Dec 27 10:44:22 PM CET 2025
==========================================

Loading modules...
Modules loaded âœ“

Setting up Python environment...
Activated venv: /pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv

Model Cache Configuration:
  Model cache workspace: /pfs/work9/workspace/scratch/ma_anhnnguy-model_cache
  HF_HOME: /pfs/work9/workspace/scratch/ma_anhnnguy-model_cache/huggingface_cache
  Models will be cached persistently across jobs

Clearing stale caches from previous jobs...
  Cache cleanup complete âœ“

Cache directories configured (job-local in $TMPDIR):
  TMPDIR: /scratch/slurm_tmpdir/job_2685550
  SLURM_JOB_ID: 2685550
  HF_HOME: /pfs/work9/workspace/scratch/ma_anhnnguy-model_cache/huggingface_cache (persistent)
  TRANSFORMERS_CACHE: /pfs/work9/workspace/scratch/ma_anhnnguy-model_cache/huggingface_cache/hub (persistent)
  TORCH_COMPILE_CACHE_DIR: /scratch/slurm_tmpdir/job_2685550/torch_compile_2685550 (job-local)
  VLLM_CACHE_ROOT: /scratch/slurm_tmpdir/job_2685550/vllm_2685550 (job-local)

Environment Information:
  Python version: Python 3.11.7
  Python path: /pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/bin/python
  vLLM version: 0.13.0
  CUDA version: V12.8.61

GPU Information:
NVIDIA A100 80GB PCIe, 81920 MiB, 81132 MiB, 35
NVIDIA A100 80GB PCIe, 81920 MiB, 81132 MiB, 32
NVIDIA A100 80GB PCIe, 81920 MiB, 81132 MiB, 32
==========================================

Pre-flight Checks:
  Python script: /pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/run_bias_evaluation.py
  Config file: /pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/config.yaml
  Output dir: /pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/results
  All packages OK âœ“
==========================================

Run Mode: custom
Runs per candidate: 30
==========================================
Running custom models: llama31-70b

Executing command:
python /pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/run_bias_evaluation.py             --config /pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/config.yaml             --models llama31-70b             --runs 30             --output /pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/results             --gpu-memory 0.90             --tensor-parallel 1             --max-model-len 4096
==========================================
âœ“ Logged in to HuggingFace successfully
============================================================
THE VISA WALL: LLM Bias Evaluation
============================================================
Config: /pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/config.yaml
Models: ['llama31-70b']
Candidates: ['anonymous', 'lukas', 'andrei', 'mehmet', 'minh', 'wei']
Runs per candidate: 30
Output directory: /pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/results
Mitigation tests: True
Max model length: 4096

============================================================
Loading model: llama31-70b (meta-llama/Llama-3.1-70B-Instruct)
============================================================
  Using max_model_len: 4096
WARNING 12-27 22:47:31 [attention.py:82] Using VLLM_ATTENTION_BACKEND environment variable is deprecated and will be removed in v0.14.0 or v1.0.0, whichever is soonest. Please use --attention-config.backend command line argument or AttentionConfig(backend=...) config field instead.
INFO 12-27 22:47:31 [utils.py:253] non-default args: {'trust_remote_code': True, 'max_model_len': 4096, 'disable_log_stats': True, 'model': 'meta-llama/Llama-3.1-70B-Instruct'}
INFO 12-27 22:47:53 [model.py:514] Resolved architecture: LlamaForCausalLM
INFO 12-27 22:47:53 [model.py:1661] Using max model len 4096
INFO 12-27 22:47:58 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=8192.
[0;36m(EngineCore_DP0 pid=142576)[0;0m INFO 12-27 22:48:01 [core.py:93] Initializing a V1 LLM engine (v0.13.0) with config: model='meta-llama/Llama-3.1-70B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-70B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False), seed=0, served_model_name=meta-llama/Llama-3.1-70B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [8192], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 512, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=142576)[0;0m INFO 12-27 22:48:04 [parallel_state.py:1203] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.21.226.36:56239 backend=nccl
[0;36m(EngineCore_DP0 pid=142576)[0;0m INFO 12-27 22:48:05 [parallel_state.py:1411] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=142576)[0;0m INFO 12-27 22:48:22 [gpu_model_runner.py:3562] Starting to load model meta-llama/Llama-3.1-70B-Instruct...
[0;36m(EngineCore_DP0 pid=142576)[0;0m INFO 12-27 22:48:26 [cuda.py:315] Using AttentionBackendEnum.FLASH_ATTN backend.
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 110.62 MiB is free. Including non-PyTorch memory, this process has 79.12 GiB memory in use. Of the allocated memory 78.62 GiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/v1/engine/core.py", line 857, in run_engine_core
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/v1/engine/core.py", line 637, in __init__
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     super().__init__(
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     self._init_executor()
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/v1/worker/gpu_worker.py", line 289, in load_model
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     raise e
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]             ^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py", line 566, in __init__
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     self.model = self._init_model(
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]                  ^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py", line 611, in _init_model
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     return LlamaModel(vllm_config=vllm_config, prefix=prefix, layer_type=layer_type)
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py", line 393, in __init__
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]                                                     ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/model_executor/models/utils.py", line 605, in make_layers
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     + [
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]       ^
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/model_executor/models/utils.py", line 606, in <listcomp>
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py", line 395, in <lambda>
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     lambda prefix: layer_type(vllm_config=vllm_config, prefix=prefix),
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py", line 302, in __init__
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     self.self_attn = LlamaAttention(
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]                      ^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py", line 165, in __init__
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     self.qkv_proj = QKVParallelLinear(
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]                     ^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/model_executor/layers/linear.py", line 935, in __init__
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     super().__init__(
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     self.quant_method.create_weights(
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     data=torch.empty(
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]          ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]   File "/pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/venv/lib/python3.11/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=142576)[0;0m ERROR 12-27 22:48:27 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 110.62 MiB is free. Including non-PyTorch memory, this process has 79.12 GiB memory in use. Of the allocated memory 78.62 GiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

==========================================
âœ— Job failed with exit code: 1
  End Time: Sat Dec 27 10:48:30 PM CET 2025

Check logs for details:
  /pfs/work9/workspace/scratch/ma_anhnnguy-topic_modeling_data/RAI/logs/visa_wall_2685550.err
==========================================

============================= JOB FEEDBACK =============================

NodeName=uc2n902
Job ID: 2685550
Cluster: uc3
User/Group: ma_anhnnguy/ma_ma
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 96
CPU Utilized: 00:00:42
CPU Efficiency: 0.17% of 06:52:48 core-walltime
Job Wall-clock time: 00:04:18
Memory Utilized: 1.23 GB
Memory Efficiency: 0.33% of 373.54 GB (373.54 GB/node)
